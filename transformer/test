#!/bin/bash
# Sweeps over data and hyperparameters.

set -euo pipefail

# Defaults.
readonly SEED=1917
readonly DATABIN=data-bin
readonly CKPTS=checkpoints

# Prediction options.
readonly BEAM=5

test() {
    local -r CP="$1"; shift
    local -r TASK="$1"; shift
    local -r SET="$1"; shift
    if [ $TASK == "g2p" ]; then
        INPUT="graphemes"
        OUTPUT="phonemes"
    else
        INPUT="phonemes"
        OUTPUT="graphemes"
    fi
    # Fairseq insists on calling the dev-set "valid"; hack around this.
    local -r FAIRSEQ_SET="${SET/dev/valid}"
    CHECKPOINT="${CP}/checkpoint_best.pt"
    RES="${CP}/${SET}.res"
    echo "Evaluating into ${RES}"
    OUT="${CP}/${SET}.out"
    TSV="${CP}/${SET}.tsv"
    # Makes raw predictions.
    fairseq-generate \
        "${DATABIN}/${TASK}/${LANGUAGE}" \
        --source-lang="${LANGUAGE}.${INPUT}" \
        --target-lang="${LANGUAGE}.${OUTPUT}" \
        --path="${CHECKPOINT}" \
        --seed="${SEED}" \
        --gen-subset="${FAIRSEQ_SET}" \
        --beam="${BEAM}" \
        --no-progress-bar \
        > "${OUT}"
    # Extracts the predictions into a TSV file.
    paste \
        <(cat "${OUT}" | grep '^T-' | cut -f2) \
        <(cat "${OUT}" | grep '^H-' | cut -f3) \
        > "${TSV}"
    # Applies the evaluation script to the TSV file.
    python ../evaluation/evaluate.py "${TSV}" > "${RES}"
    # Cleans up intermediate files.
    rm -f "${OUT}"
}

main() {
    for TASK in g2p p2g; do
        for LANGUAGE in $(ls ${DATABIN}/${TASK}); do
            for SET in train dev test; do
                test "${CKPTS}/${TASK}/${LANGUAGE}" "${TASK}" "${SET}"
            done
        done
    done
}

main
